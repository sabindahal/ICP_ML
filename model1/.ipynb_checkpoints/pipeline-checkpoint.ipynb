{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186eb03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in: saved_model\n",
      "Model reloaded from saved_model folder\n",
      "Forward latency: 7.93 ms\n"
     ]
    }
   ],
   "source": [
    "# Milestone 2 â€“ Model 1: Deskewed Red-Channel CNN-OCR (Local)\n",
    "\n",
    "\n",
    "import os, time, cv2, torch, torch.nn as nn, joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Setup\n",
    "SAVE_DIR = Path(\"saved_model\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Preprocessing\n",
    "def deskew_red(img):\n",
    "    \"\"\"Deskew the image and keep only the red channel.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "    angle = 0\n",
    "    if lines is not None:\n",
    "        angles = [theta for rho, theta in lines[:, 0]]\n",
    "        angle = (np.mean(angles) - np.pi/2) * 180/np.pi\n",
    "    (h, w) = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    b,g,r = cv2.split(img)\n",
    "    red_only = cv2.merge([np.zeros_like(r), np.zeros_like(r), r])\n",
    "    gray = cv2.cvtColor(red_only, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.resize(gray, (128,32))\n",
    "\n",
    "# CNN-OCR model\n",
    "class OCRNet(nn.Module):\n",
    "    def __init__(self, nclass=80):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(64*8,128,num_layers=2,\n",
    "                             bidirectional=True,batch_first=True)\n",
    "        self.fc = nn.Linear(256,nclass)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        b,c,h,w = x.size()\n",
    "        x = x.permute(0,3,1,2).reshape(b,w,-1)\n",
    "        x,_ = self.lstm(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Build and save model\n",
    "model = OCRNet()\n",
    "torch.save(model.state_dict(), SAVE_DIR/\"model.pt\")\n",
    "joblib.dump(model, SAVE_DIR/\"model.joblib\")\n",
    "print(\"Model saved in:\", SAVE_DIR)\n",
    "\n",
    "# Load and save model\n",
    "model_loaded = joblib.load(SAVE_DIR/\"model.joblib\")\n",
    "print(\"Model reloaded from saved_model folder\")\n",
    "\n",
    "# Run sample prediction\n",
    "dataset = load_dataset(\"lansinuote/ocr_id_card\", split=\"train[:1]\")\n",
    "img = np.array(dataset[0][\"image\"])\n",
    "cv2.imwrite(\"sample.jpg\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "proc = deskew_red(cv2.imread(\"sample.jpg\"))\n",
    "tensor = torch.tensor(proc/255.0).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    t0 = time.perf_counter()\n",
    "    _ = model_loaded(tensor)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "print(f\"Forward latency: {(t1-t0)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4efde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
