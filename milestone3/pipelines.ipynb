{
 "cells": [
  {
   "cell_type": "code",
   "id": "4a94368c48a7c528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:03:38.119517Z",
     "start_time": "2025-12-15T15:03:29.704491Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pytesseract\n",
    "import re\n",
    "import time\n",
    "import easyocr"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max's PC\\githubML\\ICP_ML\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "aa9164e562ce3a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:04:03.259286Z",
     "start_time": "2025-12-15T15:03:49.059937Z"
    }
   },
   "source": "ds = load_dataset(\"lansinuote/ocr_id_card\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since lansinuote/ocr_id_card couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\Max's PC\\.cache\\huggingface\\datasets\\lansinuote___ocr_id_card\\default\\0.0.0\\6a7fd6ba549e99b9a3517fc9a56c4e3377e43e05 (last modified on Tue Sep 23 15:08:13 2025).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2bbb752c848bc125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:04:59.618133Z",
     "start_time": "2025-12-15T15:04:59.590489Z"
    }
   },
   "source": [
    "# okay time for some actual functionality: let's make an accuracy checker\n",
    "def accuracyChecker(words, testData):\n",
    "    name = testData[0]['word']\n",
    "    accuracy = 0\n",
    "    yearFound = False\n",
    "    monthFound = False\n",
    "    dayFound = False\n",
    "    IDFound = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i] == name:\n",
    "            accuracy += 1\n",
    "        if re.fullmatch(r\"\\d{4}\", words[i]) and not yearFound:\n",
    "            if 2025 > int(words[i]) >= 1900:\n",
    "                accuracy += 1\n",
    "                yearFound = True\n",
    "        if re.fullmatch(r\"\\d{1,2}\", words[i]) and not monthFound:\n",
    "            if 12 > int(words[i]) >= 1:\n",
    "                accuracy += 1\n",
    "                monthFound = True\n",
    "        if re.fullmatch(r\"\\d{1,2}\", words[i]) and not dayFound:\n",
    "            if 31 > int(words[i]) >= 1:\n",
    "                accuracy += 1\n",
    "                dayFound = True\n",
    "        if re.fullmatch(r\"\\d{18}\", words[i]) and not IDFound:\n",
    "            accuracy += 1\n",
    "            IDFound = True\n",
    "    return accuracy / 5\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "980f7ae7061b9a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T21:50:05.848957Z",
     "start_time": "2025-12-11T21:49:54.075149Z"
    }
   },
   "source": [
    "# okay gonna run all the data through the whole pipeline, this should make it possible to change a pipeline and compute average accuracy of that pipeline\n",
    "\n",
    "accuracy = []\n",
    "latency = []\n",
    "numImages = len(ds['train'])\n",
    "numImages = 10\n",
    "for imgNum in range(numImages):\n",
    "    # collect an image from the dataset and turn it into an array for edge detection, use greyscale\n",
    "    currImg = ds['train'][imgNum]['image']\n",
    "    testingImageArray = np.array(currImg)\n",
    "    edgeDetectionArray = cv2.cvtColor(testingImageArray, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(edgeDetectionArray, 100, 200)\n",
    "\n",
    "    # do a hough lines transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 75, None, 50, 10)\n",
    "    linesTest = np.zeros(edges.shape) + 250\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        cv2.line(linesTest, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # find the angles at which each line lies\n",
    "    theta = np.zeros(len(lines))\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        if abs(l[3] - l[1]) == 0:\n",
    "            # horizontal line\n",
    "            theta[i] = 0\n",
    "        else:\n",
    "            theta[i] = math.atan(abs(l[2] - l[0])/abs(l[3] - l[1]))\n",
    "\n",
    "    # find smallest angle greater than pi/4\n",
    "    optTheta = 100\n",
    "    optIndex = 0\n",
    "    for k in range(len(theta)):\n",
    "        if theta[k] > np.pi/4:\n",
    "            if theta[k] < optTheta:\n",
    "                optTheta = theta[k]\n",
    "                optIndex = k\n",
    "    mostHorz = np.float32(lines[optIndex][0])\n",
    "    # this actually ends up being the least horizontal of the still pretty horizontal lines, deals with noise from extra lines created from the text\n",
    "\n",
    "    # find some points to warp the image, use the midpoint of the lines offset a bit, and the new destination of the endpoints of the least horizontal but still horizontal line\n",
    "    mdpnt = [(mostHorz[0] + mostHorz[2])/2,(mostHorz[1] + mostHorz[3])/2]\n",
    "    adjustment = 100\n",
    "    if mdpnt[1] > 250:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "    else:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "\n",
    "    # warp it\n",
    "    M = cv2.getAffineTransform(initialPts, finalPts)\n",
    "    warpedImg = cv2.warpAffine(testingImageArray, M, (testingImageArray.shape[1], testingImageArray.shape[0]))\n",
    "\n",
    "    # red it\n",
    "    redshiftImg = warpedImg\n",
    "    for m in range(warpedImg.shape[0]):\n",
    "        for n in range(warpedImg.shape[1]):\n",
    "            redshiftImg[m][n][1] = 0\n",
    "            redshiftImg[m][n][2] = 0\n",
    "\n",
    "    # tesseract it, also find latency\n",
    "    start = time.time()\n",
    "    wordsRaw = pytesseract.image_to_string(redshiftImg, lang='chi_sim')\n",
    "    stop = time.time()\n",
    "    latency.append(stop - start)\n",
    "\n",
    "    # clean and tokenize the data from OCR\n",
    "    words = wordsRaw.replace(\" \",\"\").splitlines()\n",
    "    testingData = ds['train'][imgNum]['ocr']\n",
    "\n",
    "    pattern = r'\\d+|[\\u4e00-\\u9fff]+|[A-Za-z]+|\\s|[^\\w\\s]'\n",
    "    tokens = []\n",
    "    for i in range(len(words)):\n",
    "        tokens.append(re.findall(pattern, words[i]))\n",
    "\n",
    "    # flatten it out\n",
    "    wordsData = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            wordsData.append(tokens[i][j])\n",
    "\n",
    "    # run the accuracy checker on the final data\n",
    "    accuracy.append(accuracyChecker(wordsData, testingData))\n",
    "\n",
    "print(\"Average accuracy: \", np.mean(accuracy))\n",
    "print(\"Average latency: \", np.mean(latency))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.5\n",
      "Average latency:  0.960825252532959\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T21:53:12.735703Z",
     "start_time": "2025-12-11T21:52:45.939540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here will be an easyOCR pipeline\n",
    "\n",
    "accuracy = []\n",
    "latency = []\n",
    "numImages = len(ds['train'])\n",
    "numImages = 10\n",
    "reader = easyocr.Reader(['ch_sim'])\n",
    "for imgNum in range(numImages):\n",
    "    # collect an image from the dataset and turn it into an array for edge detection, use greyscale\n",
    "    currImg = ds['train'][imgNum]['image']\n",
    "    testingImageArray = np.array(currImg)\n",
    "    edgeDetectionArray = cv2.cvtColor(testingImageArray, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(edgeDetectionArray, 100, 200)\n",
    "\n",
    "    # do a hough lines transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 75, None, 50, 10)\n",
    "    linesTest = np.zeros(edges.shape) + 250\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        cv2.line(linesTest, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # find the angles at which each line lies\n",
    "    theta = np.zeros(len(lines))\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        if abs(l[3] - l[1]) == 0:\n",
    "            # horizontal line\n",
    "            theta[i] = 0\n",
    "        else:\n",
    "            theta[i] = math.atan(abs(l[2] - l[0])/abs(l[3] - l[1]))\n",
    "\n",
    "    # find smallest angle greater than pi/4\n",
    "    optTheta = 100\n",
    "    optIndex = 0\n",
    "    for k in range(len(theta)):\n",
    "        if theta[k] > np.pi/4:\n",
    "            if theta[k] < optTheta:\n",
    "                optTheta = theta[k]\n",
    "                optIndex = k\n",
    "    mostHorz = np.float32(lines[optIndex][0])\n",
    "    # this actually ends up being the least horizontal of the still pretty horizontal lines, deals with noise from extra lines created from the text\n",
    "\n",
    "    # find some points to warp the image, use the midpoint of the lines offset a bit, and the new destination of the endpoints of the least horizontal but still horizontal line\n",
    "    mdpnt = [(mostHorz[0] + mostHorz[2])/2,(mostHorz[1] + mostHorz[3])/2]\n",
    "    adjustment = 100\n",
    "    if mdpnt[1] > 250:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "    else:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "\n",
    "    # warp it\n",
    "    M = cv2.getAffineTransform(initialPts, finalPts)\n",
    "    warpedImg = cv2.warpAffine(testingImageArray, M, (testingImageArray.shape[1], testingImageArray.shape[0]))\n",
    "\n",
    "    # red it\n",
    "    redshiftImg = warpedImg\n",
    "    for m in range(warpedImg.shape[0]):\n",
    "        for n in range(warpedImg.shape[1]):\n",
    "            redshiftImg[m][n][1] = 0\n",
    "            redshiftImg[m][n][2] = 0\n",
    "\n",
    "    # easyocr it\n",
    "    start = time.time()\n",
    "    results = reader.readtext(redshiftImg)\n",
    "    stop = time.time()\n",
    "    latency.append(stop - start)\n",
    "\n",
    "    # snag the words\n",
    "    wordsRaw = []\n",
    "    for res in results:\n",
    "        wordsRaw.append(res[1])\n",
    "\n",
    "    # clean and tokenize the data from OCR\n",
    "    words = []\n",
    "    for w in wordsRaw:\n",
    "        w_clean = w.replace(\" \", \"\")\n",
    "        words.append(w_clean)\n",
    "\n",
    "    testingData = ds['train'][imgNum]['ocr']\n",
    "\n",
    "    pattern = r'\\d+|[\\u4e00-\\u9fff]+|[A-Za-z]+|\\s|[^\\w\\s]'\n",
    "    tokens = []\n",
    "    for i in range(len(words)):\n",
    "        tokens.append(re.findall(pattern, words[i]))\n",
    "\n",
    "    # flatten it out\n",
    "    wordsData = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            wordsData.append(tokens[i][j])\n",
    "\n",
    "    # run the accuracy checker on the final data\n",
    "    accuracy.append(accuracyChecker(wordsData, testingData))\n",
    "\n",
    "print(\"Average accuracy: \", np.mean(accuracy))\n",
    "print(\"Average latency: \", np.mean(latency))\n",
    "\n"
   ],
   "id": "aed99a0976661755",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.0\n",
      "Average latency:  2.148895239830017\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:11:42.576353Z",
     "start_time": "2025-12-15T15:11:42.550573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# going to make a pipeline selector function. First start with preprocessing\n",
    "\n",
    "def preprocessing(img):\n",
    "    testingImageArray = np.array(img)\n",
    "    edgeDetectionArray = cv2.cvtColor(testingImageArray, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(edgeDetectionArray, 100, 200)\n",
    "\n",
    "    # do a hough lines transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 75, None, 50, 10)\n",
    "    linesTest = np.zeros(edges.shape) + 250\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        cv2.line(linesTest, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # find the angles at which each line lies\n",
    "    theta = np.zeros(len(lines))\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        if abs(l[3] - l[1]) == 0:\n",
    "            # horizontal line\n",
    "            theta[i] = 0\n",
    "        else:\n",
    "            theta[i] = math.atan(abs(l[2] - l[0])/abs(l[3] - l[1]))\n",
    "\n",
    "    # find smallest angle greater than pi/4\n",
    "    optTheta = 100\n",
    "    optIndex = 0\n",
    "    for k in range(len(theta)):\n",
    "        if theta[k] > np.pi/4:\n",
    "            if theta[k] < optTheta:\n",
    "                optTheta = theta[k]\n",
    "                optIndex = k\n",
    "    mostHorz = np.float32(lines[optIndex][0])\n",
    "    # this actually ends up being the least horizontal of the still pretty horizontal lines, deals with noise from extra lines created from the text\n",
    "\n",
    "    # find some points to warp the image, use the midpoint of the lines offset a bit, and the new destination of the endpoints of the least horizontal but still horizontal line\n",
    "    mdpnt = [(mostHorz[0] + mostHorz[2])/2,(mostHorz[1] + mostHorz[3])/2]\n",
    "    adjustment = 100\n",
    "    if mdpnt[1] > 250:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "    else:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "\n",
    "    # warp it\n",
    "    M = cv2.getAffineTransform(initialPts, finalPts)\n",
    "    warpedImg = cv2.warpAffine(testingImageArray, M, (testingImageArray.shape[1], testingImageArray.shape[0]))\n",
    "\n",
    "    # red it\n",
    "    redshiftImg = warpedImg\n",
    "    for m in range(warpedImg.shape[0]):\n",
    "        for n in range(warpedImg.shape[1]):\n",
    "            redshiftImg[m][n][1] = 0\n",
    "            redshiftImg[m][n][2] = 0\n",
    "    return redshiftImg"
   ],
   "id": "fbfac28261c86c96",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:16:08.035162Z",
     "start_time": "2025-12-15T15:16:08.008968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tesseract model:\n",
    "def chooseTesseract(img, testingData):\n",
    "    start = time.time()\n",
    "    wordsRaw = pytesseract.image_to_string(img, lang='chi_sim')\n",
    "    stop = time.time()\n",
    "    latency = stop - start\n",
    "\n",
    "    # clean and tokenize the data from OCR\n",
    "    words = wordsRaw.replace(\" \",\"\").splitlines()\n",
    "\n",
    "    pattern = r'\\d+|[\\u4e00-\\u9fff]+|[A-Za-z]+|\\s|[^\\w\\s]'\n",
    "    tokens = []\n",
    "    for i in range(len(words)):\n",
    "        tokens.append(re.findall(pattern, words[i]))\n",
    "\n",
    "    # flatten it out\n",
    "    wordsData = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            wordsData.append(tokens[i][j])\n",
    "\n",
    "    # run the accuracy checker on the final data\n",
    "    accuracy = accuracyChecker(wordsData, testingData)\n",
    "    return accuracy, latency"
   ],
   "id": "2ddb6adffed8b68c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:28:42.159364Z",
     "start_time": "2025-12-15T15:28:42.146289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# easyOCR model\n",
    "def chooseEasyOCR(img, testingData):\n",
    "    reader = easyocr.Reader(['ch_sim'])\n",
    "    start = time.time()\n",
    "    results = reader.readtext(img)\n",
    "    stop = time.time()\n",
    "    latency = stop - start\n",
    "\n",
    "    # snag the words\n",
    "    wordsRaw = []\n",
    "    for res in results:\n",
    "        wordsRaw.append(res[1])\n",
    "\n",
    "    # clean and tokenize the data from OCR\n",
    "    words = []\n",
    "    for w in wordsRaw:\n",
    "        w_clean = w.replace(\" \", \"\")\n",
    "        words.append(w_clean)\n",
    "\n",
    "    pattern = r'\\d+|[\\u4e00-\\u9fff]+|[A-Za-z]+|\\s|[^\\w\\s]'\n",
    "    tokens = []\n",
    "    for i in range(len(words)):\n",
    "        tokens.append(re.findall(pattern, words[i]))\n",
    "\n",
    "    # flatten it out\n",
    "    wordsData = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            wordsData.append(tokens[i][j])\n",
    "\n",
    "    # run the accuracy checker on the final data\n",
    "    accuracy = accuracyChecker(wordsData, testingData)\n",
    "    return accuracy, latency"
   ],
   "id": "cc72baca60da7973",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:21:14.183649Z",
     "start_time": "2025-12-15T15:21:14.170153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model choosing function, 0 for tesseract, 1 for easyOCR\n",
    "def chooseModel(choice, img, testingData):\n",
    "    processedImg = preprocessing(img)\n",
    "    if choice == 0:\n",
    "        accuracy, latency = chooseTesseract(processedImg, testingData)\n",
    "        return accuracy, latency\n",
    "    elif choice == 1:\n",
    "        accuracy, latency = chooseEasyOCR(processedImg, testingData)\n",
    "        return accuracy, latency\n",
    "    else:\n",
    "        return \"invalid choice\""
   ],
   "id": "53e20de5508a45fb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:30:43.043218Z",
     "start_time": "2025-12-15T15:30:00.882209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example of choosing and calculating average accuracy and latency:\n",
    "accuracyTesseract = []\n",
    "latencyTesseract = []\n",
    "accuracyEasyOCR = []\n",
    "latencyEasyOCR = []\n",
    "numImages = len(ds['train'])\n",
    "numImages = 10\n",
    "for imgNum in range(numImages):\n",
    "    currImg = ds['train'][imgNum]['image']\n",
    "    testingData = ds['train'][imgNum]['ocr']\n",
    "    if imgNum % 2 == 0:\n",
    "        accuracy, latency = chooseModel(imgNum % 2, currImg, testingData)\n",
    "        accuracyTesseract.append(accuracy)\n",
    "        latencyTesseract.append(latency)\n",
    "    elif imgNum % 2 == 1:\n",
    "        accuracy, latency = chooseModel(imgNum % 2, currImg, testingData)\n",
    "        accuracyEasyOCR.append(accuracy)\n",
    "        latencyEasyOCR.append(latency)\n",
    "\n",
    "print(\"Accuracy for tesseract: \", np.mean(accuracyTesseract))\n",
    "print(\"Latency for tesseract: \", np.mean(latencyTesseract))\n",
    "print(\"Accuracy for EasyOCR: \", np.mean(accuracyEasyOCR))\n",
    "print(\"Latency for EasyOCR: \", np.mean(latencyEasyOCR))\n"
   ],
   "id": "cab2326eec9d3ac4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for tesseract:  0.5599999999999999\n",
      "Latency for tesseract:  1.3606929779052734\n",
      "Accuracy for EasyOCR:  0.0\n",
      "Latency for EasyOCR:  2.9744070053100584\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d23eebbc5638e45c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
