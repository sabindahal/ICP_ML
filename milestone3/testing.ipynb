{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:36:06.943613Z",
     "start_time": "2025-12-15T20:35:54.299153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pytesseract\n",
    "import re\n",
    "import time\n",
    "import easyocr"
   ],
   "id": "af0062823e1034b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max's PC\\githubML\\ICP_ML\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:36:12.847516Z",
     "start_time": "2025-12-15T20:36:06.947420Z"
    }
   },
   "cell_type": "code",
   "source": "ds = load_dataset(\"lansinuote/ocr_id_card\")",
   "id": "439981c8b5619c78",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:36:25.694012Z",
     "start_time": "2025-12-15T20:36:25.678170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# okay time for some actual functionality: let's make an accuracy checker\n",
    "def accuracyChecker(words, testData):\n",
    "    name = testData[0]['word']\n",
    "    accuracy = 0\n",
    "    yearFound = False\n",
    "    monthFound = False\n",
    "    dayFound = False\n",
    "    IDFound = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i] == name:\n",
    "            accuracy += 1\n",
    "        if re.fullmatch(r\"\\d{4}\", words[i]) and not yearFound:\n",
    "            if 2025 > int(words[i]) >= 1900:\n",
    "                accuracy += 1\n",
    "                yearFound = True\n",
    "        if re.fullmatch(r\"\\d{1,2}\", words[i]) and not monthFound:\n",
    "            if 12 > int(words[i]) >= 1:\n",
    "                accuracy += 1\n",
    "                monthFound = True\n",
    "        if re.fullmatch(r\"\\d{1,2}\", words[i]) and not dayFound:\n",
    "            if 31 > int(words[i]) >= 1:\n",
    "                accuracy += 1\n",
    "                dayFound = True\n",
    "        if re.fullmatch(r\"\\d{18}\", words[i]) and not IDFound:\n",
    "            accuracy += 1\n",
    "            IDFound = True\n",
    "    return accuracy / 5\n"
   ],
   "id": "dfb71825692a63c7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:37:59.676964Z",
     "start_time": "2025-12-15T20:37:55.728288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = []\n",
    "latency = []\n",
    "numImages = len(ds['train'])\n",
    "numImages = 1\n",
    "for imgNum in range(numImages):\n",
    "    # collect an image from the dataset and turn it into an array for edge detection, use greyscale\n",
    "    currImg = ds['train'][imgNum]['image']\n",
    "    testingImageArray = np.array(currImg)\n",
    "    edgeDetectionArray = cv2.cvtColor(testingImageArray, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(edgeDetectionArray, 100, 200)\n",
    "\n",
    "    # do a hough lines transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 75, None, 50, 10)\n",
    "    linesTest = np.zeros(edges.shape) + 250\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        cv2.line(linesTest, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # find the angles at which each line lies\n",
    "    theta = np.zeros(len(lines))\n",
    "    for i in range(0, len(lines)):\n",
    "        l = lines[i][0]\n",
    "        if abs(l[3] - l[1]) == 0:\n",
    "            # horizontal line\n",
    "            theta[i] = 0\n",
    "        else:\n",
    "            theta[i] = math.atan(abs(l[2] - l[0])/abs(l[3] - l[1]))\n",
    "\n",
    "    # find smallest angle greater than pi/4\n",
    "    optTheta = 100\n",
    "    optIndex = 0\n",
    "    for k in range(len(theta)):\n",
    "        if theta[k] > np.pi/4:\n",
    "            if theta[k] < optTheta:\n",
    "                optTheta = theta[k]\n",
    "                optIndex = k\n",
    "    mostHorz = np.float32(lines[optIndex][0])\n",
    "    # this actually ends up being the least horizontal of the still pretty horizontal lines, deals with noise from extra lines created from the text\n",
    "\n",
    "    # find some points to warp the image, use the midpoint of the lines offset a bit, and the new destination of the endpoints of the least horizontal but still horizontal line\n",
    "    mdpnt = [(mostHorz[0] + mostHorz[2])/2,(mostHorz[1] + mostHorz[3])/2]\n",
    "    adjustment = 100\n",
    "    if mdpnt[1] > 250:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] - adjustment]])\n",
    "    else:\n",
    "        initialPts = np.float32([[mostHorz[0], mostHorz[1]],\n",
    "                                 [mostHorz[2], mostHorz[3]],\n",
    "                                 [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "        finalPts = np.float32([[mostHorz[0], mdpnt[1]],\n",
    "                               [mostHorz[2], mdpnt[1]],\n",
    "                               [mdpnt[0], mdpnt[1] + adjustment]])\n",
    "\n",
    "    # warp it\n",
    "    M = cv2.getAffineTransform(initialPts, finalPts)\n",
    "    warpedImg = cv2.warpAffine(testingImageArray, M, (testingImageArray.shape[1], testingImageArray.shape[0]))\n",
    "\n",
    "    # red it\n",
    "    redshiftImg = warpedImg\n",
    "    for m in range(warpedImg.shape[0]):\n",
    "        for n in range(warpedImg.shape[1]):\n",
    "            redshiftImg[m][n][1] = 0\n",
    "            redshiftImg[m][n][2] = 0\n",
    "\n",
    "    # tesseract it, also find latency\n",
    "    start = time.time()\n",
    "    wordsRaw = pytesseract.image_to_string(redshiftImg, lang='chi_sim')\n",
    "    stop = time.time()\n",
    "    latency.append(stop - start)\n",
    "\n",
    "    # clean and tokenize the data from OCR\n",
    "    words = wordsRaw.replace(\" \",\"\").splitlines()\n",
    "    testingData = ds['train'][imgNum]['ocr']\n",
    "\n",
    "    pattern = r'\\d+|[\\u4e00-\\u9fff]+|[A-Za-z]+|\\s|[^\\w\\s]'\n",
    "    tokens = []\n",
    "    for i in range(len(words)):\n",
    "        tokens.append(re.findall(pattern, words[i]))\n",
    "\n",
    "    # flatten it out\n",
    "    wordsData = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            wordsData.append(tokens[i][j])\n",
    "\n",
    "    # run the accuracy checker on the final data\n",
    "    accuracy.append(accuracyChecker(wordsData, testingData))\n",
    "\n",
    "print(wordsData)"
   ],
   "id": "7684d2710d7c33c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', '官加强', '女眷泉', '1988', '干', '1', '月', '21', '清南省衡阳市珠', '区', '1853198812215365', '河']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T22:17:33.397218Z",
     "start_time": "2025-12-15T22:17:24.094212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here will be an easyOCR pipeline\n",
    "\n",
    "accuracy = []\n",
    "latency = []\n",
    "numImages = len(ds['train'])\n",
    "numImages = 1\n",
    "reader = easyocr.Reader(['ch_sim'])\n",
    "for imgNum in range(numImages):\n",
    "    # collect an image from the dataset and turn it into an array for edge detection, use greyscale\n",
    "    currImg = ds['train'][imgNum]['image']\n",
    "    testingImageArray = np.array(currImg)\n",
    "    # greyscale it\n",
    "    grey = cv2.cvtColor(testingImageArray, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # gaussian blur\n",
    "    grey = cv2.GaussianBlur(grey, (5,5), 0)\n",
    "\n",
    "    # binary it\n",
    "    thresh = cv2.adaptiveThreshold(grey, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "\n",
    "    # easyocr it\n",
    "    start = time.time()\n",
    "    results = reader.readtext(thresh)\n",
    "    stop = time.time()\n",
    "    latency.append(stop - start)\n",
    "\n",
    "    # snag words\n",
    "    testing = []\n",
    "    for m in range(len(results)):\n",
    "        if results[m][2] > .25:\n",
    "            testing.append(results[m][1])\n",
    "\n",
    "    testingData = ds['train'][imgNum]['ocr']\n",
    "\n",
    "    # check accuracy\n",
    "    accuracy.append(accuracyChecker(testing, testingData))\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ],
   "id": "6b180f3f0ea18922",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:39:34.870050Z",
     "start_time": "2025-12-15T20:39:34.839751Z"
    }
   },
   "cell_type": "code",
   "source": "print(results)",
   "id": "6ce10238d42a92aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T22:09:36.259749Z",
     "start_time": "2025-12-15T22:09:36.176003Z"
    }
   },
   "cell_type": "code",
   "source": "decipher = [([[np.int32(123), np.int32(139)], [np.int32(151), np.int32(139)], [np.int32(151), np.int32(159)], [np.int32(123), np.int32(159)]], '止#', np.float64(0.00021269982427132527)), ([[np.int32(206), np.int32(156)], [np.int32(264), np.int32(156)], [np.int32(264), np.int32(186)], [np.int32(206), np.int32(186)]], '艮 &', np.float64(0.03267718479037285)), ([[np.int32(125), np.int32(168)], [np.int32(196), np.int32(168)], [np.int32(196), np.int32(200)], [np.int32(125), np.int32(200)]], '1  女', np.float64(0.29385551937228865)), ([[np.int32(130), np.int32(216)], [np.int32(158), np.int32(216)], [np.int32(158), np.int32(240)], [np.int32(130), np.int32(240)]], '+1', np.float64(0.040283392915826326)), ([[np.int32(170), np.int32(206)], [np.int32(212), np.int32(206)], [np.int32(212), np.int32(236)], [np.int32(170), np.int32(236)]], '1帔', np.float64(0.005673569689775284)), ([[np.int32(135), np.int32(257)], [np.int32(161), np.int32(257)], [np.int32(161), np.int32(277)], [np.int32(135), np.int32(277)]], '卫牛', np.float64(0.022190657852689474)), ([[np.int32(177), np.int32(275)], [np.int32(197), np.int32(275)], [np.int32(197), np.int32(299)], [np.int32(177), np.int32(299)]], '区', np.float64(0.13102118594386614)), ([[np.int32(190), np.int32(346)], [np.int32(218), np.int32(346)], [np.int32(218), np.int32(370)], [np.int32(190), np.int32(370)]], '5', np.float64(0.780059804776613)), ([[np.float64(159.2802656784306), np.float64(128.3885579247043)], [np.float64(219.29805341057522), np.float64(122.73663001235035)], [np.float64(221.7197343215694), np.float64(156.6114420752957)], [np.float64(161.70194658942478), np.float64(162.26336998764967)]], '[', np.float64(0.0021989887930565916)), ([[np.float64(206.98198161801108), np.float64(201.78017977981216)], [np.float64(297.72193181960137), np.float64(189.73861696164815)], [np.float64(301.01801838198895), np.float64(217.21982022018784)], [np.float64(210.27806818039866), np.float64(230.26138303835185)]], '412031 #', np.float64(0.0389764017291661)), ([[np.float64(168.57002829714983), np.float64(246.9420169782899)], [np.float64(311.7178083825546), np.float64(224.52422873364245)], [np.float64(316.4299717028502), np.float64(257.05798302171013)], [np.float64(173.2821916174454), np.float64(279.4757712663576)]], '染裔箸[召市#耳', np.float64(7.434269243581871e-06)), ([[np.float64(224.0), np.float64(343.0)], [np.float64(381.84985206210285), np.float64(318.0628003285702)], [np.float64(386.0), np.float64(343.0)], [np.float64(227.15014793789715), np.float64(368.9371996714298)]], '64183158812215385', np.float64(0.43798913544342083)), ([[np.float64(139.65465441200737), np.float64(356.5201198532081)], [np.float64(194.7364862842489), np.float64(349.0077221232863)], [np.float64(197.34534558799263), np.float64(370.4798801467919)], [np.float64(142.2635137157511), np.float64(378.9922778767137)]], '4息阜', np.float64(0.002058092394927222))]",
   "id": "fc744ed297aa8fbb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T22:15:44.354891Z",
     "start_time": "2025-12-15T22:15:44.339216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing = []\n",
    "for i in range(len(decipher)):\n",
    "    if decipher[i][2] > .25:\n",
    "        testing.append(decipher[i][1])\n",
    "print(accuracyChecker(testing, testingData))"
   ],
   "id": "eba93c92b8db6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9e8ee389bb04bc88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
